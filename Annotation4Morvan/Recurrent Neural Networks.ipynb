{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set hyper-parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should notice that: in RNN for image classification, time_step could be the height of images, as:\n",
    "Treat the height as the time axis for a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1\n",
    "batch_size = 64\n",
    "time_step = 28    #rnn time step/ image height\n",
    "input_size = 28   #rnn input size/image width\n",
    "lr =0.01  #learning rate\n",
    "download_MNIST = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acuquisiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torchvision.datasets.FashionMNIST(root='C:/Users/Cesare/DeeplearningwirtPytorch/data/FashionMNIST',train=True, \n",
    "                                               transform=transforms.ToTensor(),download=False)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 28, 28])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = torchvision.datasets.FashionMNIST(root='C:/Users/Cesare/DeeplearningwirtPytorch/data/FashionMNIST',train=False, \n",
    "                                               transform=transforms.ToTensor(),download=False)\n",
    "test_x =test_data.data.type(torch.FloatTensor)[:2000]/255\n",
    "test_y = test_data.targets[:2000]\n",
    "print(test_data.data.shape )\n",
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rnn =nn.LSTM(input_size = input_size, hidden_size=64, num_layers=1,batch_first=True) #batch first设置batch和timestep的顺序\n",
    "        #input size 是单行的图像的数据的长度\n",
    "        #hidden_size是LSTM的隐层状态的维数：每个LSTM单元或者Timestep输出的ht的维度，\n",
    "        #num_layersRNN层的个数，竖直方向上堆叠的多个相同个数单元的层数:与timestep时间轴垂直\n",
    "        #------# 注意：此处rnn的return并非单个值，而是r_out, (h_n, h_c)，也就是说在传递时，也会传递这些内容\n",
    "        #同时，下一层如果也是rnn，则会导入h_n 和h_c\n",
    "        self.out = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #x(batch, time step,input_size)\n",
    "        #r_out shape(batch, time step, out size)\n",
    "        #h_n shape(n_layers, batch, hidden size)-hidden n 主线程与分线程的hidden state\n",
    "        #h_c shape(n_layers, batch, hidden size)-hidden c\n",
    "        r_out, (h_n, h_c) =self.rnn(x, None)   #None指的是这是第一个rnn层，因此没有前置的hidden state\n",
    "        out = self.out(r_out[:,-1,:])#(batch, time_step, inputsize)此处只要最后一个time step的输出\n",
    "        return out  #(batch，inputsize) 二维数组无需压缩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |train_loss:2.3408 |test accuracy:0.10\n",
      "Epoch: 0 |train_loss:1.3854 |test accuracy:0.50\n",
      "Epoch: 0 |train_loss:1.0184 |test accuracy:0.65\n",
      "Epoch: 0 |train_loss:0.7086 |test accuracy:0.70\n",
      "Epoch: 0 |train_loss:0.7835 |test accuracy:0.71\n",
      "Epoch: 0 |train_loss:0.7483 |test accuracy:0.75\n",
      "Epoch: 0 |train_loss:0.5411 |test accuracy:0.76\n",
      "Epoch: 0 |train_loss:0.7909 |test accuracy:0.78\n",
      "Epoch: 0 |train_loss:0.4114 |test accuracy:0.78\n",
      "Epoch: 0 |train_loss:0.6390 |test accuracy:0.80\n",
      "Epoch: 0 |train_loss:0.5654 |test accuracy:0.80\n",
      "Epoch: 0 |train_loss:0.4797 |test accuracy:0.81\n",
      "Epoch: 0 |train_loss:0.3651 |test accuracy:0.81\n",
      "Epoch: 0 |train_loss:0.5916 |test accuracy:0.81\n",
      "Epoch: 0 |train_loss:0.5281 |test accuracy:0.81\n",
      "Epoch: 0 |train_loss:0.3837 |test accuracy:0.84\n",
      "Epoch: 0 |train_loss:0.6841 |test accuracy:0.83\n",
      "Epoch: 0 |train_loss:0.4085 |test accuracy:0.84\n",
      "Epoch: 0 |train_loss:0.3178 |test accuracy:0.83\n",
      "[9 2 1 1 6 1 4 6 5 7] prediction number\n",
      "tensor([9, 2, 1, 1, 6, 1, 4, 6, 5, 7]) real number\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch):\n",
    "    for step, (x,y) in enumerate(train_loader):\n",
    "        x = x.view(-1,28,28) #reshape x to (batch, time_step, data width)\n",
    "        output = rnn(x)\n",
    "        loss = loss_func(output, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step%50 ==0:\n",
    "            test_output = rnn(test_x)\n",
    "            pred_y = torch.max(test_output,1)[1].squeeze() #此处max，dim=1读取inputsize上的最大值及index\n",
    "            #获得的torch.max（test_output,1)是（max_value, index）格式。\n",
    "            #使用[1]可以获得index，也就是相当于使用了argmax函数获得了内容\n",
    "            #squeeze将内容压缩到二维与test_y比较\n",
    "            accuracy = float(sum(pred_y ==test_y))/float(test_y.size(0))\n",
    "            print('Epoch:',epoch,'|train_loss:%.4f'%loss.data.numpy(),'|test accuracy:%.2f'%accuracy)\n",
    "\n",
    "test_output = rnn(test_x[:10].view(-1, 28, 28))\n",
    "pred_y = torch.max(test_output, 1)[1].numpy() #转化为numpy数组打印\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10], 'real number')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
